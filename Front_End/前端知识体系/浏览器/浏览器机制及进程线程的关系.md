# 浏览器机制以及进程线程的关系

> [从输入URL到页面加载的过程？如何由一道题完善自己的前端知识体系！](https://segmentfault.com/a/1190000013662126)

"在浏览器输入url到页面渲染，中间发生了什么"

从这一道题目来完善自己的前端知识体系

知识体系中，最重要的是骨架，脉络。有了骨架后，才方便填充细节。所以，先梳理下回答这道题的主干流程：

1. 从浏览器接收到url到开启网络请求线程（这一部分可以展示浏览器的机制以及线程之间的关系）

2. 开启网络线程到发出一个完整的http请求（这一部分涉及到dns查询，tcp/ip请示，五层因特网协议栈等知识）

3. 从服务器接收到请求到对应后台接收请求（这一部分可能涉及到负载均衡，安全拦截以及后台内部的处理等等）

4. 后台和前台的http交互（这一部分包括http头部、响应码、报文结构、cookie等知识，可以提下静态资源的cookie优化，以及编码解码，如gzip压缩等）

5. 单独拎出来的缓存问题，http的缓存（这部分包括http缓存头部，etag，catch-control等）

6. 浏览器接收到http数据包后的解析流程（解析html-词法分析然后解析成dom树、解析css生成css规则树、合并成render树，然后layout、painting渲染、复合图层的合成、GPU绘制、外链资源的处理、loaded和domcontentloaded等）

7. CSS的可视化格式模型（元素的渲染规则，如包含块，控制框，BFC，IFC等概念）

8. JS引擎解析过程（JS的解释阶段，预处理阶段，执行阶段生成执行上下文，VO，作用域链、回收机制等等）

9. 其它（可以拓展不同的知识模块，如跨域，web安全，hybrid模式等等内容）

# 从浏览器接收url到开启网络请求线程

这一部分展开的内容是：浏览器进程/线程模型，JS的运行机制

## 区分进程和线程

先看看下面这个形象的比喻：

- 进程是一个工厂，工厂有它的独立资源

- 工厂之间相互独立

- 线程是工厂中的工人，多个工人协作完成任务

- 工厂内有一个或多个工人

- 工人之间共享空间

再完善完善概念:

- 工厂的资源 -> 系统分配的内存（独立的一块内存）

- 工厂之间的相互独立 -> 进程之间相互独立

- 多个工人协作完成任务 -> 多个线程在进程中协作完成任务

- 工厂内有一个或多个工人 -> 一个进程由一个或多个线程组成

- 工人之间共享空间 -> 同一进程下的各个线程之间共享程序的内存空间（包括代码段、数据集、堆等）

所以**进程是cpu资源分配的最小单位（系统会给它分配内存）**

- 进程是cpu资源分配的最小单位（是能拥有资源和独立运行的最小单位）

- 线程是cpu调度的最小单位（线程是建立在进程的基础上的一次程序运行单位，一个进程中可以有多个线程）

> 不同进程之间也可以通信，不过代价较大
> 现在，一般通用的叫法：单线程与多线程，都是指在一个进程内的单和多。（所以核心还是得属于一个进程才行）

## 多进程的浏览器

理解了进程与线程了区别后，接下来对浏览器进行一定程度上的认识：（先看下简化

- 浏览器是多进程的

- 浏览器之所以能够运行，是因为系统给它的进程分配了资源（cpu、内存）

- 简单点理解，每打开一个Tab页，就相当于创建了一个独立的浏览器进程。

浏览器是多进程的，有一个主控进程，以及每一个tab页面都会新开一个进程（某些情况下多个tab会合并进程）

如下图：

![](https://segmentfault.com/img/remote/1460000012925878?w=900&h=539)

> 打开`chrome任务管理器的方法`：在浏览头部标签页旁边的空白区域，`右键`就可以弹出有任务管理器的面板.或者`Chrome的更多工具 -> 任务管理器`

从`chrome任务管理器`可以看到浏览器进程可能包括主控进程，插件扩展进程，GPU，tab页（浏览器内核）等等

- Browser进程：浏览器的主进程（负责协调、主控），只有一个

  - 负责浏览器界面显示，与用户交互。如前进，后退等

  - 负责各个页面的管理，创建和销毁其他进程

  - 将Renderer进程得到的内存中的Bitmap，绘制到用户界面上

  - 网络资源的管理，下载等

- 第三方插件扩展进程：每种类型的插件对应一个进程，仅当使用该插件时才创建

- GPU进程：最多一个，用于3D绘制

- 浏览器渲染进程（浏览器内核）（Renderer进程，内部是多线程的）：默认每个Tab页面一个进程，互不影响（有时候会优化，如多个空白tab会合并成一个进程）

  - 主要作用： 控制页面渲染，脚本执行，事件处理等

> 浏览器中打开一个网页相当于新起了一个进程（进程内有自己的多线程）

### 浏览器多进程的优势

相比于单进程浏览器，多进程有如下优点：

- 避免单个page crash影响整个浏览器

- 避免第三方插件crash影响整个浏览器

- 多进程充分利用多核优势

- 方便使用沙盒模型隔离插件等进程，提高浏览器稳定性

> 简单点理解：如果浏览器是单进程，那么某个Tab页崩溃了，就影响了整个浏览器，体验有多差；同理如果是单进程，插件崩溃了也会影响整个浏览器；而且多进程还有其它的诸多优势。。。
> 当然，内存等资源消耗也会更大，有点空间换时间的意思。

### 重点是浏览器内核（渲染进程）

作为前端一枚，我们这里重点关注一下**渲染进程**

可以这样理解，页面的渲染，JS的执行，事件的循环，都在这个进程内进行。

**浏览器的渲染进程是多线程的**，那么接下来看看它都包含了哪些线程（列举一些主要常驻线程）：

- GUI渲染线程

  - 负责渲染浏览器界面，解析HTML，CSS，构建DOM树和RenderObject树，布局和绘制等。
  
  - 当界面需要重绘（Repaint）或由于某种操作引发回流(reflow)时，该线程就会执行

  - 注意，GUI渲染线程与JS引擎线程是互斥的，当JS引擎执行时GUI线程会被挂起（相当于被冻结了），GUI更新会被保存在一个队列中等到JS引擎空闲时立即被执行。

- JS引擎线程

  - 也称为JS内核，负责处理Javascript脚本程序。（例如V8引擎）

  - JS引擎线程负责解析Javascript脚本，运行代码。

  - JS引擎一直等待着任务队列中任务的到来，然后加以处理，一个Tab页（renderer进程）中无论什么时候都只有一个JS线程在运行JS程序

  - 同样注意，GUI渲染线程与JS引擎线程是互斥的，所以如果JS执行的时间过长，这样就会造成页面的渲染不连贯，导致页面渲染加载阻塞。

- 事件触发线程

  - 归属于浏览器而不是JS引擎，用来控制事件循环（可以理解，JS引擎自己都忙不过来，需要浏览器另开线程协助）

  - 当JS引擎执行代码块如setTimeOut时（也可来自浏览器内核的其他线程,如鼠标点击、AJAX异步请求等），会将对应任务添加到事件线程中

  - 当对应的事件符合触发条件被触发时，该线程会把事件添加到待处理队列的队尾，等待JS引擎的处理

  - 注意，由于JS的单线程关系，所以这些待处理队列中的事件都得排队等待JS引擎处理（当JS引擎空闲时才会去执行）

- 定时触发器线程

  - 传说中的setInterval与setTimeout所在线程

  - 浏览器定时计数器并不是由JavaScript引擎计数的,（因为JavaScript引擎是单线程的, 如果处于阻塞线程状态就会影响记计时的准确）

  - 因此通过单独线程来计时并触发定时（计时完毕后，添加到事件队列中，等待JS引擎空闲后执行）

  - 注意，W3C在HTML标准中规定，规定要求setTimeout中低于4ms的时间间隔算为4ms。

- 异步http请求线程
 
  - 在XMLHttpRequest在连接后是通过浏览器新开一个线程请求

  - 将检测到状态变更时，如果设置有回调函数，异步线程就产生状态变更事件，将这个回调再放入事件队列中。再由JavaScript引擎执行。

![](https://segmentfault.com/img/remote/1460000012925880?w=287&h=577)

> 再说一点，为什么JS引擎是单线程的？额，这个问题其实应该没有标准答案，譬如，可能仅仅是因为由于多线程的复杂性，譬如多线程操作一般要加锁，因此最初设计时选择了单线程。。。

## Browser进程和浏览器内核（Renderer进程）的通信过程

以浏览器解析URL到页面渲染为例：

- Browser进程收到用户请求，首先需要获取页面内容（譬如通过网络下载资源），随后将该任务通过RendererHost接口传递给Render进程

- Renderer进程的Renderer接口收到消息，简单解释后，交给渲染线程，然后开始渲染

  - 渲染线程接收请求，加载网页并渲染网页，这其中可能需要Browser进程获取资源和需要GPU进程来帮助渲染

  - 当然可能会有JS线程操作DOM（这样可能会造成回流并重绘）

  - 最后Render进程将结果传递给Browser进程

- Browser进程接收到结果并将结果绘制出来

这里绘一张简单的图：（很简化）

![](https://segmentfault.com/img/remote/1460000012925881?w=470&h=325)

至此，应该对浏览器的运作有了一定理解了，现在注意几个问题

## GUI渲染线程与JS引擎线程互斥

由于JavaScript是可操纵DOM的，如果在修改这些元素属性同时渲染界面（即JS线程和UI线程同时运行），那么渲染线程前后获得的元素数据就可能不一致了。

因此为了防止渲染出现不可预期的结果，浏览器设置GUI渲染线程与JS引擎为互斥的关系，当JS引擎执行时GUI线程会被挂起，

GUI更新则会被保存在一个队列中等到JS引擎线程空闲时立即被执行。

## JS阻塞页面加载

譬如，假设JS引擎正在进行巨量的计算，此时就算GUI有更新，也会被保存到队列中，等待JS引擎空闲后执行。
然后，由于巨量计算，所以JS引擎很可能很久很久后才能空闲，自然会感觉到巨卡无比。

所以，要尽量避免JS执行时间过长，这样就会造成页面的渲染不连贯，导致页面渲染加载阻塞的感觉。

## WebWorker，JS的多线程？

前文中有提到JS引擎是单线程的，而且JS执行时间过长会阻塞页面，那么JS就真的对cpu密集型计算无能为力么？

所以，后来HTML5中支持了Web Worker

MDN的官方解释是：

> Web Worker为Web内容在后台线程中运行脚本提供了一种简单的方法。线程可以执行任务而不干扰用户界面
一个worker是使用一个构造函数创建的一个对象(e.g. Worker()) 运行一个命名的JavaScript文件
这个文件包含将在工作线程中运行的代码; workers 运行在另一个全局上下文中,不同于当前的window
因此，使用 window快捷方式获取当前全局的范围 (而不是self) 在一个 Worker 内将返回错误

可以这么理解：

- 创建Worker时，JS引擎向浏览器申请开一个子线程（子线程是浏览器开的，完全受主线程控制，而且不能操作DOM）

- JS引擎线程与worker线程间通过特定的方式通信（postMessage API，需要通过序列化对象来与线程交互特定的数据）

所以，如果有非常耗时的工作，请单独开一个Worker线程，这样里面不管如何翻天覆地都不会影响JS引擎主线程，

只待计算出结果后，将结果通信给主线程即可，perfect!

> 而且注意下，JS引擎是单线程的，这一点的本质仍然未改变，Worker可以理解是浏览器给JS引擎开的外挂，专门用来解决那些大量计算问题

## WebWorker与SharedWorker

既然都到了这里，就再提一下SharedWorker（避免后续将这两个概念搞混）

- WebWorker只属于某个页面，不会和其他页面的Render进程（浏览器内核进程）共享

  - 所以Chrome在Render进程中（每一个Tab页就是一个render进程）创建一个新的线程来运行Worker中的JavaScript程序。

- SharedWorker是浏览器所有页面共享的，不能采用与Worker同样的方式实现，因为它不隶属于某个Render进程，可以为多个Render进程共享使用

- 所以Chrome浏览器为SharedWorker单独创建一个进程来运行JavaScript程序，在浏览器中每个相同的JavaScript只存在一个SharedWorker进程，不管它被创建多少次。

看到这里，应该就很容易明白了，本质上就是进程和线程的区别。SharedWorker由独立的进程管理，WebWorker只是属于render进程下的一个线程


## 解析URL

输入URL后，会进行解析（URL的本质就是统一资源定位符）

URL一般包括以下几个部分：

- `protocol`: 协议头，如`http`，`https`，`ftp`等

- `host`: 主机域名或IP地址

- `port`: 端口

- `path`: 目录或路由路径

- `query`: 查询参数

- `fragment`: `#`后的hash值，一般用来定位到某个位置

## 网络请求都是单独的线程

每次网络请求时都需要开辟单独的线程进行，譬如如果URL解析到http协议，就会新建一个网络线程去处理资源下载

因此浏览器会根据解析出得协议，开辟一个网络线程，前往请求资源（这里，暂时理解为是浏览器内核开辟的，如有错误，后续修复）

## 开启网络线程到发出一个完整的http请求

这一部分主要内容包括：dns查询，tcp/ip请求构建，五层因特网协议栈等等

仍然是先梳理主干，有些详细的过程不展开（因为展开的话内容过多）

### DNS查询得到IP

如果输入的是域名，需要进行dns解析成IP，大致流程：

- 如果浏览器有缓存，直接使用浏览器缓存，否则使用本机缓存，再没有的话就是用host

- 如果本地没有，就向dns域名服务器查询（当然，中间可能还会经过路由，也有缓存等），查询到对应的IP

注意，域名查询时有可能是经过了CDN调度器的（如果有cdn存储功能的话）

而且，需要知道dns解析是很耗时的，因此如果解析域名过多，会让首屏加载变得过慢，可以考虑dns-prefetch优化

### tcp/ip请求

http的本质就是`tcp/ip`请求

需要了解3次握手规则建立连接以及断开连接时的四次挥手

tcp将http长报文划分为短报文，通过三次握手与服务端建立连接，进行可靠传输

**三次握手的步骤：（抽象派）**

```
客户端：hello，你是server么？
服务端：hello，我是server，你是client么
客户端：yes，我是client
```

建立连接成功后，接下来就正式传输数据

然后，待到断开连接时，需要进行四次挥手（因为是全双工的，所以需要四次挥手）

**四次挥手的步骤：（抽象派）**

```
主动方：我已经关闭了向你那边的主动通道了，只能被动接收了
被动方：收到通道关闭的信息
被动方：那我也告诉你，我这边向你的主动通道也关闭了
主动方：最后收到数据，之后双方无法通信
```

**tcp/ip的并发限制**

- 浏览器对同一域名下并发的tcp连接是有限制的（2-10个不等）

- 而且在http1.0中往往一个资源下载就需要对应一个tcp/ip请求

- 所以针对这个瓶颈，又出现了很多的资源优化方案

**get和post的区别**

get和post虽然本质都是tcp/ip，但两者除了在http层面外，在tcp/ip层面也有区别。

get会产生一个tcp数据包，post两个

具体就是：

- get请求时，浏览器会把headers和data一起发送出去，服务器响应200（返回数据），

- post请求时，浏览器先发送headers，服务器响应100 continue，

浏览器再发送data，服务器响应200（返回数据）。

再说一点，这里的区别是specification（规范）层面，而不是implementation（对规范的实现）

## 五层因特网协议栈

其实就是一个概念： 从客户端发出http请求到服务器接收，中间会经过一系列的流程。

简括就是：

**从应用层的发送http请求，到传输层通过三次握手建立tcp/ip连接，再到网络层的ip寻址，再到数据链路层的封装成帧，最后到物理层的利用物理介质传输。**

当然，服务端的接收就是反过来的步骤

五层因特网协议栈其实就是：

1. 应用层(dns,http) DNS解析成IP并发送http请求

2. 传输层(tcp,udp) 建立tcp连接（三次握手）

3. 网络层(IP,ARP) IP寻址

4. 数据链路层(PPP) 封装成帧

5. 物理层(利用物理介质传输比特流) 物理传输（然后传输的时候通过双绞线，电磁波等各种介质）

当然，其实也有一个完整的OSI七层框架，与之相比，多了会话层、表示层。

OSI七层框架：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层

> 表示层：主要处理两个通信系统中交换信息的表示方式，包括数据格式交换，数据加密与解密，数据压缩与终端类型转换等

> 会话层：它具体管理不同用户和进程之间的对话，如控制登陆和注销过程

# 从服务器接收到请求到对应后台接收到请求

服务端在接收到请求时，内部会进行很多的处理

这里由于不是专业的后端分析，所以只是简单的介绍下，不深入

## 负载均衡

对于大型的项目，由于并发访问量很大，所以往往一台服务器是吃不消的，所以一般会有若干台服务器组成一个集群，然后配合反向代理实现负载均衡

当然了，负载均衡不止这一种实现方式，这里不深入...

简单的说：

用户发起的请求都指向调度服务器（反向代理服务器，譬如安装了nginx控制负载均衡），然后调度服务器根据实际的调度算法，分配不同的请求给对应集群中的服务器执行，然后调度器等待实际服务器的HTTP响应，并将它反馈给用户

## 后台的处理

一般后台都是部署到容器中的，所以一般为：

- 先是容器接受到请求（如tomcat容器）

- 然后对应容器中的后台程序接收到请求（如java程序）

- 然后就是后台会有自己的统一处理，处理完后响应响应结果

概括下：

- 一般有的后端是有统一的验证的，如安全拦截，跨域验证

- 如果这一步不符合规则，就直接返回了相应的http报文（如拒绝请求等）

- 然后当验证通过后，才会进入实际的后台代码，此时是程序接收到请求，然后执行（譬如查询数据库，大量计算等等）

- 等程序执行完毕后，就会返回一个http响应包（一般这一步也会经过多层封装）

- 然后就是将这个包从后端发送到前端，完成交互

## 后台和前台的http交互

- 前后端交互时，http报文作为信息的载体

- 所以http是一块很重要的内容，这一部分重点介绍它

### http报文结构

报文一般包括了：通用头部，请求/响应头部，请求/响应体

**通用头部**

这也是开发人员见过的最多的信息，包括如下：

- Request Url: 请求的web服务器地址

- Request Method: 请求方式
（Get、POST、OPTIONS、PUT、HEAD、DELETE、CONNECT、TRACE）

- Status Code: 请求的返回状态码，如200代表成功

- Remote Address: 请求的远程服务器地址（会转为IP）

譬如，在跨域拒绝时，可能是method为options，状态码为404/405等（当然，实际上可能的组合有很多）

其中，Method的话一般分为两批次：

> HTTP1.0定义了三种请求方法： GET, POST 和 HEAD方法。
以及几种Additional Request Methods：PUT、DELETE、LINK、UNLINK

> HTTP1.1定义了八种请求方法：GET、POST、HEAD、OPTIONS, PUT, DELETE, TRACE 和 CONNECT 方法

这里面最常用到的就是状态码，很多时候都是通过状态码来判断，如（列举几个最常见的）：

- 200——表明该请求被成功地完成，所请求的资源发送回客户端

- 304——自从上次请求后，请求的网页未修改过，请客户端使用本地缓存

- 400——客户端请求有错（譬如可以是安全模块拦截）

- 401——请求未经授权

- 403——禁止访问（譬如可以是未登录时禁止）

- 404——资源未找到

- 500——服务器内部错误

- 503——服务不可用

再列举下大致不同范围状态的意义

- 1xx——指示信息，表示请求已接收，继续处理

- 2xx——成功，表示请求已被成功接收、理解、接受

- 3xx——重定向，要完成请求必须进行更进一步的操作

- 4xx——客户端错误，请求有语法错误或请求无法实现

- 5xx——服务器端错误，服务器未能实现合法的请求

![](https://segmentfault.com/img/remote/1460000013662133?w=509&h=594)

**请求/响应头部**

常用的请求头部（部分）：

- Accept: 接收类型，表示浏览器支持的MIME类型
（对标服务端返回的Content-Type）

- Accept-Encoding：浏览器支持的压缩类型,如gzip等,超出类型不能接收

- Content-Type：客户端发送出去实体内容的类型

- Cache-Control: 指定请求和响应遵循的缓存机制，如no-cache

- If-Modified-Since：对应服务端的Last-Modified，用来匹配看文件是否变动，只能精确到1s之内，http1.0中

- Expires：缓存控制，在这个时间内不会请求，直接使用缓存，http1.0，而且是服务端时间

- Max-age：代表资源在本地缓存多少秒，有效时间内不会请求，而是使用缓存，http1.1中

- If-None-Match：对应服务端的ETag，用来匹配文件内容是否改变（非常精确），http1.1中

- Cookie: 有cookie并且同域访问时会自动带上

- Connection: 当浏览器与服务器通信时对于长连接如何进行处理,如keep-alive

- Host：请求的服务器URL

- Origin：最初的请求是从哪里发起的（只会精确到端口）,Origin比Referer更尊重隐私

- Referer：该页面的来源URL(适用于所有类型的请求，会精确到详细页面地址，csrf拦截常用到这个字段)

- User-Agent：用户客户端的一些必要信息，如UA头部等

**常用的响应头部（部分）：**

- Access-Control-Allow-Headers: 服务器端允许的请求Headers

- Access-Control-Allow-Methods: 服务器端允许的请求方法

- Access-Control-Allow-Origin: 服务器端允许的请求Origin头部（譬如为*）

- Content-Type：服务端返回的实体内容的类型

- Date：数据从服务器发送的时间

- Cache-Control：告诉浏览器或其他客户，什么环境可以安全的缓存文档

- Last-Modified：请求资源的最后修改时间

- Expires：应该在什么时候认为文档已经过期,从而不再缓存它

- Max-age：客户端的本地资源应该缓存多少秒，开启了Cache-Control后有效

- ETag：请求变量的实体标签的当前值

- Set-Cookie：设置和页面关联的cookie，服务器通过这个头部把cookie传给客户端

- Keep-Alive：如果客户端有keep-alive，服务端也会有响应（如timeout=38）

- Server：服务器的一些相关信息

一般来说，请求头部和响应头部是匹配分析的。

譬如，请求头部的Accept要和响应头部的Content-Type匹配，否则会报错

譬如，跨域请求时，请求头部的Origin要匹配响应头部的Access-Control-Allow-Origin，否则会报跨域错误

譬如，在使用缓存时，请求头部的If-Modified-Since、If-None-Match分别和响应头部的Last-Modified、ETag对应

**请求/响应实体**

http请求时，除了头部，还有消息实体，一般来说

请求实体中会将一些需要的参数都放入进入（用于post请求）。

譬如实体中可以放参数的序列化形式（a=1&b=2这种），或者直接放表单对象（Form Data对象，上传时可以夹杂参数以及文件），等等

而一般响应实体中，就是放服务端需要传给客户端的内容

一般现在的接口请求时，实体中就是对于的信息的json格式，而像页面请求这种，里面就是直接放了一个html字符串，然后浏览器自己解析并渲染。

**CRLF**

CRLF（Carriage-Return Line-Feed），意思是回车换行，一般作为分隔符存在

请求头和实体消息之间有一个CRLF分隔，响应头部和响应实体之间用一个CRLF分隔

一般来说（分隔符类别）：

```
CRLF->Windows-style
LF->Unix Style
CR->Mac Style
```

如下图是对某请求的http报文结构的简要分析

![](https://segmentfault.com/img/remote/1460000013662134?w=659&h=884)


## cookie以及优化

cookie是浏览器的一种本地存储方式，一般用来帮助客户端和服务端通信的，常用来进行身份校验，结合服务端的session使用。

场景如下（简述）：

```
在登陆页面，用户登陆了

此时，服务端会生成一个session，session中有对于用户的信息（如用户名、密码等）

然后会有一个sessionid（相当于是服务端的这个session对应的key）

然后服务端在登录页面中写入cookie，值就是:jsessionid=xxx

然后浏览器本地就有这个cookie了，以后访问同域名下的页面时，自动带上cookie，自动检验，在有效时间内无需二次登陆。
```

上述就是cookie的常用场景简述（当然了，实际情况下得考虑更多因素）

一般来说，cookie是不允许存放敏感信息的（千万不要明文存储用户名、密码），因为非常不安全，如果一定要强行存储，首先，一定要在cookie中设置httponly（这样就无法通过js操作了），另外可以考虑rsa等非对称加密（因为实际上，浏览器本地也是容易被攻克的，并不安全）

另外，由于在同域名的资源请求时，浏览器会默认带上本地的cookie，针对这种情况，在某些场景下是需要优化的。

譬如以下场景：

> 客户端在域名A下有cookie（这个可以是登陆时由服务端写入的）
然后在域名A下有一个页面，页面中有很多依赖的静态资源（都是域名A的，譬如有20个静态资源）
此时就有一个问题，页面加载，请求这些静态资源时，浏览器会默认带上cookie
也就是说，这20个静态资源的http请求，每一个都得带上cookie，而实际上静态资源并不需要cookie验证
此时就造成了较为严重的浪费，而且也降低了访问速度（因为内容更多了）

当然了，针对这种场景，是有优化方案的（多域名拆分）。具体做法就是：

- 将静态资源分组，分别放到不同的域名下（如static.base.com）

- 而page.base.com（页面所在域名）下请求时，是不会带上static.base.com域名的cookie的，所以就避免了浪费

说到了多域名拆分，这里再提一个问题，那就是：

- 在移动端，如果请求的域名数过多，会降低请求速度（因为域名整套解析流程是很耗费时间的，而且移动端一般带宽都比不上pc）

- 此时就需要用到一种优化方案：dns-prefetch（让浏览器空闲时提前解析dns域名，不过也请合理使用，勿滥用）

关于cookie的交互，可以看下图总结

![](https://segmentfault.com/img/remote/1460000013662135?w=916&h=603)

### gzip压缩

首先，明确gzip是一种压缩格式，需要浏览器支持才有效（不过一般现在浏览器都支持），
而且gzip压缩效率很好（高达70%左右）

然后gzip一般是由apache、tomcat等web服务器开启

当然服务器除了gzip外，也还会有其它压缩格式（如deflate，没有gzip高效，且不流行）

所以一般只需要在服务器上开启了gzip压缩，然后之后的请求就都是基于gzip压缩格式的，
非常方便。

## 长连接与短连接

首先看tcp/ip层面的定义：

- 长连接：一个tcp/ip连接上可以连续发送多个数据包，在tcp连接保持期间，如果没有数据包发送，需要双方发检测包以维持此连接，一般需要自己做在线维持（类似于心跳包）

- 短连接：通信双方有数据交互时，就建立一个tcp连接，数据发送完成后，则断开此tcp连接

然后在http层面：

- http1.0中，默认使用的是短连接，也就是说，浏览器没进行一次http操作，就建立一次连接，任务结束就中断连接，譬如每一个静态资源请求时都是一个单独的连接

- http1.1起，默认使用长连接，使用长连接会有这一行Connection: keep-alive，在长连接的情况下，当一个网页打开完成后，客户端和服务端之间用于传输http的tcp连接不会关闭，如果客户端再次访问这个服务器的页面，会继续使用这一条已经建立的连接

> 注意： keep-alive不会永远保持，它有一个持续时间，一般在服务器中配置（如apache），另外长连接需要客户端和服务器都支持时才有效


## http 2.0

http2.0不是https，它相当于是http的下一代规范（譬如https的请求可以是http2.0规范的）

然后简述下http2.0与http1.1的显著不同点：

- http1.1中，每请求一个资源，都是需要开启一个tcp/ip连接的，所以对应的结果是，每一个资源对应一个tcp/ip请求，由于tcp/ip本身有并发数限制，所以当资源一多，速度就显著慢下来

- http2.0中，一个tcp/ip请求可以请求多个资源，也就是说，只要一次tcp/ip请求，就可以请求若干个资源，分割成更小的帧请求，速度明显提升。

所以，如果http2.0全面应用，很多http1.1中的优化方案就无需用到了（譬如打包成精灵图，静态资源多域名拆分等）

然后简述下http2.0的一些特性：

- 多路复用（即一个tcp/ip连接可以请求多个资源）

- 首部压缩（http头部压缩，减少体积）

- 二进制分帧（在应用层跟传送层之间增加了一个二进制分帧层，改进传输性能，实现低延迟和高吞吐量）

- 服务器端推送（服务端可以对客户端的一个请求发出多个响应，可以主动通知客户端）

- 请求优先级（如果流被赋予了优先级，它就会基于这个优先级来处理，由服务器决定需要多少资源来处理该请求。）

## https

https就是安全版本的http，譬如一些支付等操作基本都是基于https的，因为http请求的安全系数太低了。

简单来看，https与http的区别就是： 在请求前，会建立ssl链接，确保接下来的通信都是加密的，无法被轻易截取分析

一般来说，如果要将网站升级成https，需要后端支持（后端需要申请证书等），然后https的开销也比http要大（因为需要额外建立安全链接以及加密等），所以一般来说http2.0配合https的体验更佳（因为http2.0更快了）

一般来说，主要关注的就是SSL/TLS的握手流程，如下（简述）：

1. 浏览器请求建立SSL链接，并向服务端发送一个随机数–Client random和客户端支持的加密方法，比如RSA加密，此时是明文传输。 

2. 服务端从中选出一组加密算法与Hash算法，回复一个随机数–Server random，并将自己的身份信息以证书的形式发回给浏览器
（证书里包含了网站地址，非对称加密的公钥，以及证书颁发机构等信息）

3. 浏览器收到服务端的证书后

  - 验证证书的合法性（颁发机构是否合法，证书中包含的网址是否和正在访问的一样），如果证书信任，则浏览器会显示一个小锁头，否则会有提示

  - 用户接收证书后（不管信不信任），浏览会生产新的随机数–Premaster secret，然后证书中的公钥以及指定的加密方法加密`Premaster secret`，发送给服务器。

  - 利用Client random、Server random和Premaster secret通过一定的算法生成HTTP链接数据传输的对称加密key-`session key`
 
  - 使用约定好的HASH算法计算握手消息，并使用生成的`session key`对消息进行加密，最后将之前生成的所有信息发送给服务端。 
 
4. 服务端收到浏览器的回复

  - 利用已知的加解密方式与自己的私钥进行解密，获取`Premaster secret`

  - 和浏览器相同规则生成`session key`

  - 使用`session key`解密浏览器发来的握手消息，并验证Hash是否与浏览器发来的一致

  - 使用`session key`加密一段握手消息，发送给浏览器

5. 浏览器解密并计算握手消息的HASH，如果与服务端发来的HASH一致，此时握手过程结束，

**之后所有的https通信数据将由之前浏览器生成的session key并利用对称加密算法进行加密**

## 单独拎出来的缓存问题，http的缓存

略

补充


HTML页面中也有一个meta标签可以控制缓存方案-Pragma

```
<META HTTP-EQUIV="Pragma" CONTENT="no-cache">
```

**Max-Age相比Expires？**

Expires使用的是服务器端的时间

但是有时候会有这样一种情况-客户端时间和服务端不同步

那这样，可能就会出问题了，造成了浏览器本地的缓存无用或者一直无法过期

所以一般http1.1后不推荐使用Expires

而Max-Age使用的是客户端本地时间的计算，因此不会有这个问题

**E-tag相比Last-Modified？**

Last-Modified：

- 表明服务端的文件最后何时改变的

- 它有一个缺陷就是只能精确到1s，

- 然后还有一个问题就是有的服务端的文件会周期性的改变，导致缓存失效

E-tag：

- 是一种指纹机制，代表文件相关指纹

- 只有文件变才会变，也只要文件变就会变

- 也没有精确时间的限制，只要文件一遍，立马E-tag就不一样了

如果同时带有E-tag和Last-Modified，服务端会优先检查E-tag

各大缓存头部的整体关系如下图

![](https://segmentfault.com/img/remote/1460000013662137?w=886&h=539)


# 解析页面流程

## 资源外链的下载

简单起见，这里将遇到的静态资源分为一下几大类（未列举所有）：

CSS样式资源
JS脚本资源
img图片类资源

遇到外链时的处理

当遇到上述的外链时，会单独开启一个下载线程去下载资源（http1.1中是每一个资源的下载都要开启一个http请求，对应一个tcp/ip链接）

遇到CSS样式资源

CSS资源的处理有几个特点：

- CSS下载时异步，不会阻塞浏览器构建DOM树

- 但是会阻塞渲染，也就是在构建render时，会等到css下载解析完毕后才进行（这点与浏览器优化有关，防止css规则不断改变，避免了重复的构建）

- 有例外，media query声明的CSS是不会阻塞渲染的

遇到JS脚本资源

- 阻塞浏览器的解析，也就是说发现一个外链脚本时，需等待脚本下载完成并执行后才会继续解析HTML

- 浏览器的优化，一般现代浏览器有优化，在脚本阻塞时，也会继续下载其它资源（当然有并发上限），但是虽然脚本可以并行下载，解析过程仍然是阻塞的，也就是说必须这个脚本执行完毕后才会接下来的解析，并行下载只是一种优化而已

- defer与async，普通的脚本是会阻塞浏览器解析的，但是可以加上defer或async属性，这样脚本就变成异步了，可以等到解析完毕后再执行

注意，defer和async是有区别的： defer是延迟执行，而async是异步执行。

- async是异步执行，异步下载完毕后就会执行，不确保执行顺序，一定在onload前，但不确定在DOMContentLoaded事件的前或后

- defer是延迟执行，在浏览器看起来的效果像是将脚本放在了body后面一样（虽然按规范应该是在DOMContentLoaded事件前，但实际上不同浏览器的优化效果不一样，也有可能在它后面）

遇到img图片类资源

遇到图片等资源时，直接就是异步下载，不会阻塞解析，下载完毕后直接用图片替换原有src的地方

# CSS的可视化格式模型




